{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29027d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (79 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/miniconda3/lib/python3.13/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "Successfully installed pandas-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7c05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CENSUS CODEBOOK SUMMARY ---\n",
      "Total Variables: 496956\n",
      "Columns: ['title', 'description', 'vintage', 'variable', 'label']\n",
      "\n",
      "--- FIRST 3 ROWS ---\n",
      "                                               title  \\\n",
      "0  Apr 1989 Current Population Survey: Basic Monthly   \n",
      "1  Apr 1989 Current Population Survey: Basic Monthly   \n",
      "2  Apr 1989 Current Population Survey: Basic Monthly   \n",
      "\n",
      "                                         description  vintage  variable  \\\n",
      "0  To provide estimates of employment, unemployme...     1989  A_ABSREA   \n",
      "1  To provide estimates of employment, unemployme...     1989   A_AG_NA   \n",
      "2  To provide estimates of employment, unemployme...     1989     A_AGE   \n",
      "\n",
      "                                         label  \n",
      "0  Labor Force-reasons for absence, pay status  \n",
      "1     Indus.&Occ.-agriculture, non-agriculture  \n",
      "2                              Demographic-age  \n",
      "\n",
      "--- DETAILED LOOK AT FIRST VARIABLE ---\n",
      "title: Apr 1989 Current Population Survey: Basic Monthly\n",
      "description: To provide estimates of employment, unemployment, and other characteristics of the general labor force, of the population as a whole, and of various subgroups of the population. Monthly labor force data for the country are used by the Bureau of Labor Statistics (BLS) to determine the distribution of funds under the Job Training Partnership Act. These data are collected through combined computer-assisted personal interviewing (CAPI) and computer-assisted telephone interviewing (CATI). In addition to the labor force data, the CPS basic funding provides annual data on work experience, income, and migration from the March Annual Demographic Supplement and on school enrollment of the population from the October Supplement. Other supplements, some of which are sponsored by other agencies, are conducted biennially or intermittently.\n",
      "vintage: 1989\n",
      "variable: A_ABSREA\n",
      "label: Labor Force-reasons for absence, pay status\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your census codebook\n",
    "file_path = \"/Users/kwatchomahinanda/Downloads/census_codebook.csv\"\n",
    "\n",
    "try:\n",
    "    census_df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(\"\\n--- CENSUS CODEBOOK SUMMARY ---\")\n",
    "    print(f\"Total Variables: {census_df.shape[0]}\")\n",
    "    print(f\"Columns: {census_df.columns.tolist()}\")\n",
    "    \n",
    "    print(\"\\n--- FIRST 3 ROWS ---\")\n",
    "    print(census_df.head(3))\n",
    "    \n",
    "    print(\"\\n--- DETAILED LOOK AT FIRST VARIABLE ---\")\n",
    "    for col in census_df.columns:\n",
    "        print(f\"{col}: {census_df.iloc[0][col]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6630a2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BWDC EDUCATION DATA ---\n",
      "Shape: (312, 5)\n",
      "Columns: ['sex', 'educational_attainment', 'year', 'race_or_ethnicity', 'rate']... (Total: 5)\n",
      "\n",
      "First 2 rows:\n",
      "      sex       educational_attainment  year race_or_ethnicity  rate\n",
      "0    Male  Bachelor's or higher degree  2014             Black  21.0\n",
      "1  Female  Bachelor's or higher degree  2017          Hispanic  18.6\n",
      "\n",
      "--- DATA DICTIONARY (EXCEL) ---\n",
      "Columns: ['column_name', 'visual name', 'variable name on visual', 'visual_unique_id', 'data table', 'publisher', 'description']\n",
      "\n",
      "First 3 entries:\n",
      "         column_name                                        visual name  \\\n",
      "0               year  Median Total Assets for Households, by Race/Et...   \n",
      "1               race  Median Total Assets for Households, by Race/Et...   \n",
      "2  education_buckets  Median Total Assets for Households, by Race/Et...   \n",
      "\n",
      "      variable name on visual visual_unique_id                     data table  \\\n",
      "0                        Year           adt_01  \\nSummary Extract Public Data   \n",
      "1           Race or Ethnicity           adt_01  \\nSummary Extract Public Data   \n",
      "2  Highest Level of Education           adt_01  \\nSummary Extract Public Data   \n",
      "\n",
      "                                           publisher  \\\n",
      "0  US Federal Reserve, Survey of Consumer Finance...   \n",
      "1  US Federal Reserve, Survey of Consumer Finance...   \n",
      "2  US Federal Reserve, Survey of Consumer Finance...   \n",
      "\n",
      "                                         description  \n",
      "0                 Survey Year. YEAR from source data  \n",
      "1  Race or ethnicity of respondent.  Buckets are ...  \n",
      "2  Highest completed grade by reference person. E...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths to your BWDC files\n",
    "edu_path = \"/Users/kwatchomahinanda/Downloads/explore_data_edu_01/edu_01.csv\"\n",
    "dict_path = \"/Users/kwatchomahinanda/Downloads/explore_data_edu_01/data-dictionary.xlsx\"\n",
    "\n",
    "print(\"\\n--- BWDC EDUCATION DATA ---\")\n",
    "try:\n",
    "    edu_df = pd.read_csv(edu_path)\n",
    "    print(f\"Shape: {edu_df.shape}\")\n",
    "    print(f\"Columns: {edu_df.columns.tolist()[:10]}... (Total: {len(edu_df.columns)})\")\n",
    "    print(\"\\nFirst 2 rows:\")\n",
    "    print(edu_df.head(2))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "\n",
    "print(\"\\n--- DATA DICTIONARY (EXCEL) ---\")\n",
    "try:\n",
    "    dict_df = pd.read_excel(dict_path)\n",
    "    print(f\"Columns: {dict_df.columns.tolist()}\")\n",
    "    print(\"\\nFirst 3 entries:\")\n",
    "    print(dict_df.head(3))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Excel: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27575aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing data... please wait.\n",
      "Successfully vectorized 312 rows into the local vault.\n",
      "Vault is locked and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# 1. Setup ChromaDB (Local Persistence)\n",
    "client = chromadb.PersistentClient(path=\"./invest_atlanta_vault\")\n",
    "\n",
    "# Using a standard embedding model (will download automatically on first run)\n",
    "emb_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a collection for Education Stats\n",
    "edu_collection = client.get_or_create_collection(name=\"bwdc_education\", embedding_function=emb_fn)\n",
    "\n",
    "# 2. Load the CSV\n",
    "df = pd.read_csv(\"/Users/kwatchomahinanda/Downloads/explore_data_edu_01/edu_01.csv\")\n",
    "\n",
    "documents = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "\n",
    "print(\"Vectorizing data... please wait.\")\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # Construct a human-readable sentence for the AI to \"read\"\n",
    "    sentence = (f\"In {row['year']}, the educational attainment rate for {row['race_or_ethnicity']} \"\n",
    "                f\"{row['sex']} individuals labeled as '{row['educational_attainment']}' was {row['rate']}%.\")\n",
    "    \n",
    "    documents.append(sentence)\n",
    "    metadatas.append({\"year\": int(row['year']), \"race\": row['race_or_ethnicity']})\n",
    "    ids.append(f\"edu_row_{idx}\")\n",
    "\n",
    "# 3. Add to ChromaDB\n",
    "edu_collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(f\"Successfully vectorized {len(documents)} rows into the local vault.\")\n",
    "\n",
    "# Force-save the data to the disk (specific to Jupyter environments)\n",
    "client.heartbeat() \n",
    "print(\"Vault is locked and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd09cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RESULTS FOR: 'What is the bachelor's degree rate for Black men?' ---\n",
      "Match 1: In 2017, the educational attainment rate for Black Male individuals labeled as 'Bachelor's or higher degree' was 22.6%.\n",
      "Match 2: In 2018, the educational attainment rate for Black Male individuals labeled as 'Bachelor's or higher degree' was 23.7%.\n",
      "Match 3: In 2019, the educational attainment rate for Black Male individuals labeled as 'Bachelor's or higher degree' was 24.4%.\n"
     ]
    }
   ],
   "source": [
    "# 1. Define your question\n",
    "query = \"What is the bachelor's degree rate for Black men?\"\n",
    "\n",
    "# 2. Search the vault\n",
    "# n_results=3 means \"give me the top 3 closest matches\"\n",
    "results = edu_collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "# 3. Print the results\n",
    "print(f\"--- RESULTS FOR: '{query}' ---\")\n",
    "for i, doc in enumerate(results['documents'][0]):\n",
    "    print(f\"Match {i+1}: {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "367b3d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your database is currently hidden here: /Users/kwatchomahinanda/DATASCI 531/datasci531spring2026/Lecture_04/invest_atlanta_vault\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Your database is currently hidden here: {os.getcwd()}/invest_atlanta_vault\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffcfbd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in /opt/miniconda3/lib/python3.13/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /opt/miniconda3/lib/python3.13/site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama) (4.12.1)\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic>=2.9->ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/miniconda3/lib/python3.13/site-packages (from pydantic>=2.9->ollama) (0.4.0)\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.6.1\n"
     ]
    }
   ],
   "source": [
    "# The '!' tells Jupyter to run this in the system terminal\n",
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e872e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is thinking...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def ask_invest_atlanta(question):\n",
    "    # 1. Retrieve the top 3 relevant facts from your local ChromaDB vault\n",
    "    results = edu_collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=3\n",
    "    )\n",
    "    \n",
    "    # 2. Combine the retrieved facts into a single \"Context\" block\n",
    "    context = \"\\n\".join(results['documents'][0])\n",
    "    \n",
    "    # 3. Create the prompt for Llama 3\n",
    "    # We tell the AI to ONLY use the data we just found.\n",
    "    prompt = f\"\"\"\n",
    "    You are a professional Data Assistant for Invest Atlanta. \n",
    "    Use the following specific statistics to answer the user's question. \n",
    "    If the data isn't in the context, say you don't have that specific data point.\n",
    "\n",
    "    DATA CONTEXT:\n",
    "    {context}\n",
    "\n",
    "    USER QUESTION: \n",
    "    {question}\n",
    "\n",
    "    YOUR RESPONSE:\n",
    "    \"\"\"\n",
    "\n",
    "    # 4. Send it to your local Llama 3 model\n",
    "    response = ollama.generate(model='llama3-grants', prompt=prompt)\n",
    "    \n",
    "    return response['response']\n",
    "\n",
    "# --- TEST IT OUT ---\n",
    "user_q = \"Can you summarize the bachelor's degree trends for Black men between 2017 and 2019?\"\n",
    "print(f\"Assistant is thinking...\\n\")\n",
    "print(ask_invest_atlanta(user_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b828afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Loading Census Codebook\n",
      "======================================================================\n",
      "âœ… File found!\n",
      "ðŸ“¦ File size: 359.63 MB\n",
      "\n",
      "======================================================================\n",
      "ATTEMPTING TO LOAD FIRST 10 ROWS...\n",
      "======================================================================\n",
      "âœ… Successfully loaded sample!\n",
      "\n",
      "ðŸ“Š Dataset Info:\n",
      "   - Columns: 5\n",
      "   - Sample rows: 10\n",
      "\n",
      "ðŸ“‹ COLUMN NAMES:\n",
      "   1. title\n",
      "   2. description\n",
      "   3. vintage\n",
      "   4. variable\n",
      "   5. label\n",
      "\n",
      "ðŸ” FIRST 5 ROWS:\n",
      "                                               title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            description  vintage  variable                                        label\n",
      "0  Apr 1989 Current Population Survey: Basic Monthly  To provide estimates of employment, unemployment, and other characteristics of the general labor force, of the population as a whole, and of various subgroups of the population. Monthly labor force data for the country are used by the Bureau of Labor Statistics (BLS) to determine the distribution of funds under the Job Training Partnership Act. These data are collected through combined computer-assisted personal interviewing (CAPI) and computer-assisted telephone interviewing (CATI). In addition to the labor force data, the CPS basic funding provides annual data on work experience, income, and migration from the March Annual Demographic Supplement and on school enrollment of the population from the October Supplement. Other supplements, some of which are sponsored by other agencies, are conducted biennially or intermittently.     1989  A_ABSREA  Labor Force-reasons for absence, pay status\n",
      "1  Apr 1989 Current Population Survey: Basic Monthly  To provide estimates of employment, unemployment, and other characteristics of the general labor force, of the population as a whole, and of various subgroups of the population. Monthly labor force data for the country are used by the Bureau of Labor Statistics (BLS) to determine the distribution of funds under the Job Training Partnership Act. These data are collected through combined computer-assisted personal interviewing (CAPI) and computer-assisted telephone interviewing (CATI). In addition to the labor force data, the CPS basic funding provides annual data on work experience, income, and migration from the March Annual Demographic Supplement and on school enrollment of the population from the October Supplement. Other supplements, some of which are sponsored by other agencies, are conducted biennially or intermittently.     1989   A_AG_NA     Indus.&Occ.-agriculture, non-agriculture\n",
      "2  Apr 1989 Current Population Survey: Basic Monthly  To provide estimates of employment, unemployment, and other characteristics of the general labor force, of the population as a whole, and of various subgroups of the population. Monthly labor force data for the country are used by the Bureau of Labor Statistics (BLS) to determine the distribution of funds under the Job Training Partnership Act. These data are collected through combined computer-assisted personal interviewing (CAPI) and computer-assisted telephone interviewing (CATI). In addition to the labor force data, the CPS basic funding provides annual data on work experience, income, and migration from the March Annual Demographic Supplement and on school enrollment of the population from the October Supplement. Other supplements, some of which are sponsored by other agencies, are conducted biennially or intermittently.     1989     A_AGE                              Demographic-age\n",
      "3  Apr 1989 Current Population Survey: Basic Monthly  To provide estimates of employment, unemployment, and other characteristics of the general labor force, of the population as a whole, and of various subgroups of the population. Monthly labor force data for the country are used by the Bureau of Labor Statistics (BLS) to determine the distribution of funds under the Job Training Partnership Act. These data are collected through combined computer-assisted personal interviewing (CAPI) and computer-assisted telephone interviewing (CATI). In addition to the labor force data, the CPS basic funding provides annual data on work experience, income, and migration from the March Annual Demographic Supplement and on school enrollment of the population from the October Supplement. Other supplements, some of which are sponsored by other agencies, are conducted biennially or intermittently.     1989   A_ANYWK                             Labor Force-work\n",
      "4  Apr 1989 Current Population Survey: Basic Monthly  To provide estimates of employment, unemployment, and other characteristics of the general labor force, of the population as a whole, and of various subgroups of the population. Monthly labor force data for the country are used by the Bureau of Labor Statistics (BLS) to determine the distribution of funds under the Job Training Partnership Act. These data are collected through combined computer-assisted personal interviewing (CAPI) and computer-assisted telephone interviewing (CATI). In addition to the labor force data, the CPS basic funding provides annual data on work experience, income, and migration from the March Annual Demographic Supplement and on school enrollment of the population from the October Supplement. Other supplements, some of which are sponsored by other agencies, are conducted biennially or intermittently.     1989   A_AVAIL                    Labor Force-available job\n",
      "\n",
      "ðŸ“ˆ DATA TYPES:\n",
      "title            str\n",
      "description      str\n",
      "vintage        int64\n",
      "variable         str\n",
      "label            str\n",
      "\n",
      "âœ¨ SAMPLE DATA FROM EACH COLUMN:\n",
      "   title: 'Apr 1989 Current Population Survey: Basic Monthly'\n",
      "   description: 'To provide estimates of employment, unemployment, and other characteristics of the general labor force, of the population as a whole, and of various subgroups of the population. Monthly labor force data for the country are used by the Bureau of Labor Statistics (BLS) to determine the distribution of funds under the Job Training Partnership Act. These data are collected through combined computer-assisted personal interviewing (CAPI) and computer-assisted telephone interviewing (CATI). In addition to the labor force data, the CPS basic funding provides annual data on work experience, income, and migration from the March Annual Demographic Supplement and on school enrollment of the population from the October Supplement. Other supplements, some of which are sponsored by other agencies, are conducted biennially or intermittently.'\n",
      "   vintage: '1989'\n",
      "   variable: 'A_ABSREA'\n",
      "   label: 'Labor Force-reasons for absence, pay status'\n",
      "\n",
      "======================================================================\n",
      "END OF STEP 1\n",
      "======================================================================\n",
      "\n",
      "ðŸ“¤ Please copy and paste ALL of the output above!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ============================================\n",
    "# REPLACE THIS with your actual file path\n",
    "# ============================================\n",
    "file_path = \"/Users/kwatchomahinanda/Downloads/census_codebook.csv\"\n",
    "\n",
    "print(\"STEP 1: Loading Census Codebook\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"âŒ ERROR: File not found at {file_path}\")\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"1. File name is correct\")\n",
    "    print(\"2. File is in the right location\")\n",
    "    print(\"3. You have the full path\")\n",
    "else:\n",
    "    print(f\"âœ… File found!\")\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = os.path.getsize(file_path) / (1024 * 1024)  # Convert to MB\n",
    "    print(f\"ðŸ“¦ File size: {file_size:.2f} MB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ATTEMPTING TO LOAD FIRST 10 ROWS...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        # Try reading first 10 rows\n",
    "        if file_path.endswith('.csv'):\n",
    "            df_sample = pd.read_csv(file_path, nrows=10)\n",
    "        elif file_path.endswith('.xlsx'):\n",
    "            df_sample = pd.read_excel(file_path, nrows=10)\n",
    "        else:\n",
    "            print(\"âŒ Unknown file format. Please use .csv or .xlsx\")\n",
    "            df_sample = None\n",
    "        \n",
    "        if df_sample is not None:\n",
    "            print(\"âœ… Successfully loaded sample!\")\n",
    "            print(f\"\\nðŸ“Š Dataset Info:\")\n",
    "            print(f\"   - Columns: {len(df_sample.columns)}\")\n",
    "            print(f\"   - Sample rows: {len(df_sample)}\")\n",
    "            \n",
    "            print(f\"\\nðŸ“‹ COLUMN NAMES:\")\n",
    "            for i, col in enumerate(df_sample.columns, 1):\n",
    "                print(f\"   {i}. {col}\")\n",
    "            \n",
    "            print(f\"\\nðŸ” FIRST 5 ROWS:\")\n",
    "            print(df_sample.head().to_string())\n",
    "            \n",
    "            print(f\"\\nðŸ“ˆ DATA TYPES:\")\n",
    "            print(df_sample.dtypes.to_string())\n",
    "            \n",
    "            print(f\"\\nâœ¨ SAMPLE DATA FROM EACH COLUMN:\")\n",
    "            for col in df_sample.columns:\n",
    "                sample_value = df_sample[col].iloc[0] if len(df_sample) > 0 else \"N/A\"\n",
    "                print(f\"   {col}: '{sample_value}'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading file: {type(e).__name__}\")\n",
    "        print(f\"   Details: {str(e)}\")\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRYING ALTERNATIVE METHOD (CHUNKED READING)...\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        try:\n",
    "            # Alternative: Read in chunks\n",
    "            if file_path.endswith('.csv'):\n",
    "                chunk_iterator = pd.read_csv(file_path, chunksize=100)\n",
    "                first_chunk = next(chunk_iterator)\n",
    "                \n",
    "                print(\"âœ… Loaded first chunk (100 rows)!\")\n",
    "                print(f\"\\nðŸ“Š Chunk Info:\")\n",
    "                print(f\"   - Shape: {first_chunk.shape}\")\n",
    "                print(f\"   - Columns: {len(first_chunk.columns)}\")\n",
    "                \n",
    "                print(f\"\\nðŸ“‹ COLUMN NAMES:\")\n",
    "                for i, col in enumerate(first_chunk.columns, 1):\n",
    "                    print(f\"   {i}. {col}\")\n",
    "                \n",
    "                print(f\"\\nðŸ” FIRST 5 ROWS:\")\n",
    "                print(first_chunk.head().to_string())\n",
    "                \n",
    "            else:\n",
    "                print(\"âŒ Cannot chunk-read Excel files easily.\")\n",
    "                print(\"   Suggestion: Convert to CSV first or use smaller sample\")\n",
    "                \n",
    "        except Exception as e2:\n",
    "            print(f\"âŒ Chunked reading also failed: {type(e2).__name__}\")\n",
    "            print(f\"   Details: {str(e2)}\")\n",
    "            print(\"\\nðŸ’¡ SUGGESTIONS:\")\n",
    "            print(\"   1. Make sure the file isn't corrupted\")\n",
    "            print(\"   2. Try opening it in Excel/Numbers to verify it works\")\n",
    "            print(\"   3. Convert to CSV if it's Excel\")\n",
    "            print(\"   4. Check if you have enough RAM\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF STEP 1\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ“¤ Please copy and paste ALL of the output above!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24ee38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Sample & Pattern Analysis\n",
      "======================================================================\n",
      "Loading first 1,000 rows...\n",
      "âœ… Loaded 1000 rows\n",
      "\n",
      "ðŸ“Š DATASET STATISTICS:\n",
      "   Total rows in sample: 1000\n",
      "   Unique variables: 238\n",
      "   Unique titles: 5\n",
      "   Year range: 1989 - 1989\n",
      "\n",
      "ðŸ“‹ SURVEY TYPES IN SAMPLE:\n",
      "   Found 5 different surveys:\n",
      "   1. Apr 1989 Current Population Survey: Basic Monthly... (238 variables)\n",
      "   2. Aug 1989 Current Population Survey: Basic Monthly... (238 variables)\n",
      "   3. Dec 1989 Current Population Survey: Basic Monthly... (238 variables)\n",
      "   4. Feb 1989 Current Population Survey: Basic Monthly... (238 variables)\n",
      "   5. Jan 1989 Current Population Survey: Basic Monthly... (48 variables)\n",
      "\n",
      "ðŸ”¤ VARIABLE NAME PATTERNS:\n",
      "   Sample variable codes:\n",
      "   - A_ABSREA\n",
      "   - A_AG_NA\n",
      "   - A_AGE\n",
      "   - A_ANYWK\n",
      "   - A_AVAIL\n",
      "   - A_CHKWJ\n",
      "   - A_CIVLF\n",
      "   - A_CLSWKR\n",
      "   - A_DSCWK\n",
      "   - A_DTCLWK\n",
      "   - A_DTIND\n",
      "   - A_DTOCC\n",
      "   - A_EARNRT\n",
      "   - A_EMP\n",
      "   - A_EMPHRS\n",
      "   - A_ENRCHK\n",
      "   - A_ENRLW\n",
      "   - A_ERNEL\n",
      "   - A_ERNLWT\n",
      "   - A_EXPLF\n",
      "\n",
      "ðŸ·ï¸ LABEL PATTERNS (first 30):\n",
      "   1. Labor Force-reasons for absence, pay status\n",
      "   2. Indus.&Occ.-agriculture, non-agriculture\n",
      "   3. Demographic-age\n",
      "   4. Labor Force-work\n",
      "   5. Labor Force-available job\n",
      "   6. Indus.&Occ.-interviewer check item\n",
      "   7. Labor Force-civilian labor force\n",
      "   8. Indus.&Occ.-class of worker\n",
      "   9. Labor Force-discouraged worker flag\n",
      "   10. Indus.&Occ.-detailed class of worker\n",
      "   11. Indus.&Occ.-detailed industry code\n",
      "   12. Indus.&Occ.-detailed occupation code\n",
      "   13. Earnings-interviewer check item\n",
      "   14. Labor Force-employed persons\n",
      "   15. Labor Force-reasons, hours\n",
      "   16. School Enrollment-interviewer check item\n",
      "   17. School Enrollment-enrolled/attending an inst. of educ.\n",
      "   18. Earnings-eligibility\n",
      "   19. Weight-earnings/not in labor force weight\n",
      "   20. Labor Force-employment status\n",
      "   21. Demographic-expanded relationship code\n",
      "   22. Demographic-family number\n",
      "   23. Demographic-family relationship\n",
      "   24. Demographic-family type\n",
      "   25. Weight-family weight\n",
      "   26. Earnings-family earnings top code flag\n",
      "   27. Earnings-family earnings top coded\n",
      "   28. Weight-family earnings weight\n",
      "   29. Weight-adults final weight\n",
      "   30. Labor Force-hours worked/week\n",
      "\n",
      "ðŸ” KEYWORD ANALYSIS:\n",
      "   Keyword occurrences in sample:\n",
      "   - 'household': 216 times\n",
      "   - 'age': 51 times\n",
      "   - 'race': 16 times\n",
      "   - 'employment': 9 times\n",
      "   - 'income': 8 times\n",
      "   - 'population': 0 times\n",
      "   - 'housing': 0 times\n",
      "   - 'education': 0 times\n",
      "   - 'poverty': 0 times\n",
      "   - 'median': 0 times\n",
      "\n",
      "ðŸ“Œ EXAMPLE LABELS BY KEYWORD:\n",
      "\n",
      "   Examples with 'income':\n",
      "   - Household-family income\n",
      "   - Household-family income (allocation flag)\n",
      "   - Household-family income\n",
      "   - Household-family income (allocation flag)\n",
      "   - Household-family income\n",
      "\n",
      "   Examples with 'housing':\n",
      "\n",
      "   Examples with 'population':\n",
      "\n",
      "   Examples with 'employment':\n",
      "   - Labor Force-employment status\n",
      "   - Labor Force-public employment agency\n",
      "   - Labor Force-employment status\n",
      "   - Labor Force-public employment agency\n",
      "   - Labor Force-employment status\n",
      "\n",
      "   Examples with 'education':\n",
      "\n",
      "======================================================================\n",
      "END OF STEP 2\n",
      "======================================================================\n",
      "\n",
      "ðŸ“¤ Please paste this output!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/Users/kwatchomahinanda/Downloads/census_codebook.csv\"\n",
    "\n",
    "print(\"STEP 2: Sample & Pattern Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load a larger sample (1000 rows)\n",
    "print(\"Loading first 1,000 rows...\")\n",
    "df_sample = pd.read_csv(file_path, nrows=1000)\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_sample)} rows\\n\")\n",
    "\n",
    "# Basic stats\n",
    "print(\"ðŸ“Š DATASET STATISTICS:\")\n",
    "print(f\"   Total rows in sample: {len(df_sample)}\")\n",
    "print(f\"   Unique variables: {df_sample['variable'].nunique()}\")\n",
    "print(f\"   Unique titles: {df_sample['title'].nunique()}\")\n",
    "print(f\"   Year range: {df_sample['vintage'].min()} - {df_sample['vintage'].max()}\")\n",
    "\n",
    "# Show unique survey titles\n",
    "print(f\"\\nðŸ“‹ SURVEY TYPES IN SAMPLE:\")\n",
    "print(f\"   Found {df_sample['title'].nunique()} different surveys:\")\n",
    "for i, title in enumerate(df_sample['title'].unique()[:10], 1):\n",
    "    count = len(df_sample[df_sample['title'] == title])\n",
    "    print(f\"   {i}. {title[:70]}... ({count} variables)\")\n",
    "\n",
    "# Look at variable naming patterns\n",
    "print(f\"\\nðŸ”¤ VARIABLE NAME PATTERNS:\")\n",
    "print(f\"   Sample variable codes:\")\n",
    "for var in df_sample['variable'].head(20):\n",
    "    print(f\"   - {var}\")\n",
    "\n",
    "# Look at label patterns\n",
    "print(f\"\\nðŸ·ï¸ LABEL PATTERNS (first 30):\")\n",
    "for i, label in enumerate(df_sample['label'].head(30), 1):\n",
    "    print(f\"   {i}. {label}\")\n",
    "\n",
    "# Check for keywords in labels\n",
    "print(f\"\\nðŸ” KEYWORD ANALYSIS:\")\n",
    "keywords = {\n",
    "    'income': 0,\n",
    "    'population': 0,\n",
    "    'housing': 0,\n",
    "    'employment': 0,\n",
    "    'education': 0,\n",
    "    'age': 0,\n",
    "    'race': 0,\n",
    "    'poverty': 0,\n",
    "    'household': 0,\n",
    "    'median': 0\n",
    "}\n",
    "\n",
    "for label in df_sample['label']:\n",
    "    if pd.notna(label):  # Check if not null\n",
    "        label_lower = str(label).lower()\n",
    "        for keyword in keywords:\n",
    "            if keyword in label_lower:\n",
    "                keywords[keyword] += 1\n",
    "\n",
    "print(\"   Keyword occurrences in sample:\")\n",
    "for keyword, count in sorted(keywords.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"   - '{keyword}': {count} times\")\n",
    "\n",
    "# Show some examples of each keyword\n",
    "print(f\"\\nðŸ“Œ EXAMPLE LABELS BY KEYWORD:\")\n",
    "example_keywords = ['income', 'housing', 'population', 'employment', 'education']\n",
    "\n",
    "for keyword in example_keywords:\n",
    "    print(f\"\\n   Examples with '{keyword}':\")\n",
    "    examples = df_sample[df_sample['label'].str.contains(keyword, case=False, na=False)]['label'].head(5)\n",
    "    for ex in examples:\n",
    "        print(f\"   - {ex}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF STEP 2\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ“¤ Please paste this output!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d5e564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Exploring Full Dataset Variety\n",
      "======================================================================\n",
      "Counting total rows (this may take a moment)...\n",
      "âœ… Total rows in file: 584,888\n",
      "\n",
      "ðŸ“Š Sampling from different sections...\n",
      "âœ… Sampled 1000 rows from beginning, middle, and end\n",
      "\n",
      "ðŸ“‹ ALL SURVEY TYPES IN FILE:\n",
      "   Found 4 different survey types:\n",
      "\n",
      "   1. Apr 1989 Current Population Survey: Basic Monthly... (238 vars)\n",
      "   2. Aug 1989 Current Population Survey: Basic Monthly... (238 vars)\n",
      "   3. Dec 1989 Current Population Survey: Basic Monthly... (24 vars)\n",
      "   4. Wave 7 Survey of Income and Program Participation - 2008 Panel: Topical Modules... (500 vars)\n",
      "\n",
      "ðŸ“… YEAR RANGE:\n",
      "   Oldest: 1989\n",
      "   Newest: 2008\n",
      "\n",
      "ðŸ” KEYWORD ANALYSIS (DIVERSE SAMPLE):\n",
      "   Top keywords:\n",
      "   - 'labor': 195 times\n",
      "   - 'house': 158 times\n",
      "   - 'household': 158 times\n",
      "   - 'work': 96 times\n",
      "   - 'age': 71 times\n",
      "   - 'demographic': 69 times\n",
      "   - 'family': 67 times\n",
      "   - 'total': 56 times\n",
      "   - 'earnings': 48 times\n",
      "   - 'income': 46 times\n",
      "   - 'school': 26 times\n",
      "   - 'rent': 24 times\n",
      "   - 'enrollment': 19 times\n",
      "   - 'employment': 18 times\n",
      "   - 'veteran': 14 times\n",
      "   - 'occupation': 13 times\n",
      "   - 'health': 11 times\n",
      "   - 'wage': 10 times\n",
      "   - 'salary': 8 times\n",
      "   - 'mortgage': 8 times\n",
      "   - 'race': 8 times\n",
      "   - 'insurance': 7 times\n",
      "   - 'disability': 5 times\n",
      "   - 'sex': 4 times\n",
      "   - 'poverty': 3 times\n",
      "\n",
      "ðŸ“Œ DIVERSE LABEL EXAMPLES:\n",
      "   Random sample of 30 labels from across the file:\n",
      "\n",
      "   1. AS: Ownership of solely held savings account\n",
      "   2. SU: Wave of data collection\n",
      "   3. GI: Amount of Railroad Retirement (ISS Code 2)\n",
      "   4. GI: 1st reason applying for General Asst the 2nd time\n",
      "   5. Household-reason\n",
      "   6. GI: Reason for receipt of local government pension\n",
      "   7. PE: Social Security coverage flag (ISS 1)\n",
      "   8. GI: Receipt of Social Security payments for children\n",
      "   9. RE: Total secured debt recode\n",
      "   10. School Enrollment-institution (allocation flag)\n",
      "   11. RE: Car value for first vehicle\n",
      "   12. Earnings-number of earners\n",
      "   13. PE: Medicaid coverage flag\n",
      "   14. SM: Debt on stocks/funds in own name\n",
      "   15. RE: Current value of property\n",
      "   16. AS: Amount of interest paid on mortgage owned with spouse\n",
      "   17. Labor Force-intend to look for work\n",
      "   18. IE: Amount in joint interest earning account\n",
      "   19. GI: Amount of U.S. Military retirement pay\n",
      "   20. Labor Force-wage and salary\n",
      "   21. ME: Children's dentist visits in the past 12 months\n",
      "   22. Household-interviewer check item\n",
      "   23. Labor Force-total hours worked (allocation flag)\n",
      "   24. GI: Whether ... received transportation assistance -- help with car\n",
      "   25. Geography-FIPS state code\n",
      "   26. Household-type b/c (allocation flag)\n",
      "   27. Labor Force-last work full-time job lasting 2+ weeks\n",
      "   28. SF: Total related subfamily unemployment income recode\n",
      "   29. AS: Amount of dividends credited to joint margin account\n",
      "   30. PV: How much did ... pay in child support for month 3?\n",
      "\n",
      "======================================================================\n",
      "END OF STEP 3\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/Users/kwatchomahinanda/Downloads/census_codebook.csv\"\n",
    "\n",
    "print(\"STEP 3: Exploring Full Dataset Variety\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get total row count\n",
    "print(\"Counting total rows (this may take a moment)...\")\n",
    "total_rows = sum(1 for _ in open(file_path)) - 1  # -1 for header\n",
    "print(f\"âœ… Total rows in file: {total_rows:,}\")\n",
    "\n",
    "# Sample from different parts of the file\n",
    "print(f\"\\nðŸ“Š Sampling from different sections...\")\n",
    "\n",
    "# Beginning (first 500)\n",
    "df_beginning = pd.read_csv(file_path, nrows=500)\n",
    "\n",
    "# Middle (skip to middle, read 500)\n",
    "skip_to_middle = total_rows // 2\n",
    "df_middle = pd.read_csv(file_path, skiprows=range(1, skip_to_middle), nrows=500)\n",
    "\n",
    "# End (read last 500)\n",
    "skip_to_end = total_rows - 500\n",
    "df_end = pd.read_csv(file_path, skiprows=range(1, skip_to_end), nrows=500)\n",
    "\n",
    "# Combine samples\n",
    "df_combined = pd.concat([df_beginning, df_middle, df_end], ignore_index=True)\n",
    "\n",
    "print(f\"âœ… Sampled {len(df_combined)} rows from beginning, middle, and end\")\n",
    "\n",
    "# Analyze all survey types\n",
    "print(f\"\\nðŸ“‹ ALL SURVEY TYPES IN FILE:\")\n",
    "unique_titles = df_combined['title'].unique()\n",
    "print(f\"   Found {len(unique_titles)} different survey types:\\n\")\n",
    "for i, title in enumerate(unique_titles[:20], 1):  # Show first 20\n",
    "    count = len(df_combined[df_combined['title'] == title])\n",
    "    print(f\"   {i}. {title[:80]}... ({count} vars)\")\n",
    "\n",
    "if len(unique_titles) > 20:\n",
    "    print(f\"\\n   ... and {len(unique_titles) - 20} more survey types\")\n",
    "\n",
    "# Year range\n",
    "print(f\"\\nðŸ“… YEAR RANGE:\")\n",
    "print(f\"   Oldest: {df_combined['vintage'].min()}\")\n",
    "print(f\"   Newest: {df_combined['vintage'].max()}\")\n",
    "\n",
    "# Expanded keyword analysis on diverse sample\n",
    "print(f\"\\nðŸ” KEYWORD ANALYSIS (DIVERSE SAMPLE):\")\n",
    "keywords = {\n",
    "    'income': 0, 'earnings': 0, 'wage': 0, 'salary': 0,\n",
    "    'population': 0, 'demographic': 0,\n",
    "    'housing': 0, 'house': 0, 'rent': 0, 'mortgage': 0,\n",
    "    'employment': 0, 'labor': 0, 'work': 0, 'occupation': 0,\n",
    "    'education': 0, 'school': 0, 'enrollment': 0,\n",
    "    'age': 0, 'sex': 0, 'race': 0, 'ethnicity': 0, 'hispanic': 0,\n",
    "    'poverty': 0, 'poor': 0,\n",
    "    'household': 0, 'family': 0,\n",
    "    'health': 0, 'insurance': 0, 'disability': 0,\n",
    "    'veteran': 0, 'military': 0,\n",
    "    'median': 0, 'total': 0, 'percent': 0\n",
    "}\n",
    "\n",
    "for label in df_combined['label']:\n",
    "    if pd.notna(label):\n",
    "        label_lower = str(label).lower()\n",
    "        for keyword in keywords:\n",
    "            if keyword in label_lower:\n",
    "                keywords[keyword] += 1\n",
    "\n",
    "print(\"   Top keywords:\")\n",
    "sorted_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)\n",
    "for keyword, count in sorted_keywords[:25]:  # Top 25\n",
    "    if count > 0:\n",
    "        print(f\"   - '{keyword}': {count} times\")\n",
    "\n",
    "# Show diverse label examples\n",
    "print(f\"\\nðŸ“Œ DIVERSE LABEL EXAMPLES:\")\n",
    "print(f\"   Random sample of 30 labels from across the file:\\n\")\n",
    "sample_labels = df_combined['label'].dropna().sample(min(30, len(df_combined)), random_state=42)\n",
    "for i, label in enumerate(sample_labels, 1):\n",
    "    print(f\"   {i}. {label}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF STEP 3\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f6784",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_SCHEMA = {\n",
    "    \"01_DEMOGRAPHICS\": {\n",
    "        \"description\": \"Age, sex, race, ethnicity, family composition\",\n",
    "        \"keywords\": [\"age\", \"sex\", \"race\", \"ethnicity\", \"hispanic\", \"demographic\", \n",
    "                     \"family\", \"household\", \"relationship\", \"marital\"],\n",
    "        \"subcategories\": [\n",
    "            \"Age & Gender\",\n",
    "            \"Race & Ethnicity\", \n",
    "            \"Family & Household Composition\",\n",
    "            \"Marital Status\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"02_INCOME_EARNINGS\": {\n",
    "        \"description\": \"Wages, salary, earnings, total income\",\n",
    "        \"keywords\": [\"income\", \"earnings\", \"wage\", \"salary\", \"pay\", \"revenue\"],\n",
    "        \"subcategories\": [\n",
    "            \"Household Income\",\n",
    "            \"Personal Earnings\",\n",
    "            \"Wage & Salary\",\n",
    "            \"Family Income\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"03_EMPLOYMENT_LABOR\": {\n",
    "        \"description\": \"Employment status, occupation, industry, work hours\",\n",
    "        \"keywords\": [\"employment\", \"labor\", \"work\", \"occupation\", \"industry\", \n",
    "                     \"job\", \"employed\", \"unemployed\", \"worker\", \"class of worker\"],\n",
    "        \"subcategories\": [\n",
    "            \"Employment Status\",\n",
    "            \"Occupation\",\n",
    "            \"Industry\",\n",
    "            \"Work Hours & Conditions\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"04_HOUSING\": {\n",
    "        \"description\": \"Housing units, rent, mortgage, property value\",\n",
    "        \"keywords\": [\"housing\", \"house\", \"rent\", \"mortgage\", \"property\", \n",
    "                     \"dwelling\", \"residence\", \"apartment\", \"owner\", \"renter\"],\n",
    "        \"subcategories\": [\n",
    "            \"Housing Units\",\n",
    "            \"Rent & Rental Property\",\n",
    "            \"Mortgage & Home Ownership\",\n",
    "            \"Property Value\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"05_EDUCATION\": {\n",
    "        \"description\": \"School enrollment, educational attainment, degrees\",\n",
    "        \"keywords\": [\"education\", \"school\", \"enrollment\", \"degree\", \"college\", \n",
    "                     \"university\", \"grade\", \"attainment\", \"diploma\"],\n",
    "        \"subcategories\": [\n",
    "            \"School Enrollment\",\n",
    "            \"Educational Attainment\",\n",
    "            \"Degrees & Credentials\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"06_POVERTY_ASSISTANCE\": {\n",
    "        \"description\": \"Poverty status, government assistance programs\",\n",
    "        \"keywords\": [\"poverty\", \"poor\", \"assistance\", \"welfare\", \"tanf\", \n",
    "                     \"snap\", \"food stamp\", \"medicaid\", \"ssi\", \"general assist\"],\n",
    "        \"subcategories\": [\n",
    "            \"Poverty Status\",\n",
    "            \"Government Assistance Programs\",\n",
    "            \"Social Security & Benefits\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"07_HEALTH_DISABILITY\": {\n",
    "        \"description\": \"Health insurance, disability, medical coverage\",\n",
    "        \"keywords\": [\"health\", \"insurance\", \"disability\", \"medical\", \"medicare\", \n",
    "                     \"medicaid\", \"coverage\", \"doctor\", \"dentist\"],\n",
    "        \"subcategories\": [\n",
    "            \"Health Insurance\",\n",
    "            \"Disability Status\",\n",
    "            \"Medical Access & Care\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"08_ASSETS_WEALTH\": {\n",
    "        \"description\": \"Savings, stocks, investments, assets, debt\",\n",
    "        \"keywords\": [\"asset\", \"saving\", \"stock\", \"investment\", \"account\", \n",
    "                     \"fund\", \"bond\", \"debt\", \"owe\", \"equity\"],\n",
    "        \"subcategories\": [\n",
    "            \"Savings & Accounts\",\n",
    "            \"Stocks & Investments\",\n",
    "            \"Assets & Property\",\n",
    "            \"Debt\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"09_VETERAN_MILITARY\": {\n",
    "        \"description\": \"Military service, veteran status, military benefits\",\n",
    "        \"keywords\": [\"veteran\", \"military\", \"service\", \"armed forces\", \n",
    "                     \"va\", \"retirement pay\"],\n",
    "        \"subcategories\": [\n",
    "            \"Veteran Status\",\n",
    "            \"Military Service\",\n",
    "            \"Military Benefits\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"10_GEOGRAPHY\": {\n",
    "        \"description\": \"Location codes, state, county, tract identifiers\",\n",
    "        \"keywords\": [\"geography\", \"fips\", \"state\", \"county\", \"tract\", \n",
    "                     \"location\", \"msa\", \"cbsa\"],\n",
    "        \"subcategories\": [\n",
    "            \"State & County\",\n",
    "            \"Census Tract\",\n",
    "            \"Metropolitan Area\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"11_WEIGHTS_TECHNICAL\": {\n",
    "        \"description\": \"Statistical weights, flags, technical variables\",\n",
    "        \"keywords\": [\"weight\", \"flag\", \"allocation\", \"imputation\", \"recode\", \n",
    "                     \"check item\", \"interviewer\"],\n",
    "        \"subcategories\": [\n",
    "            \"Survey Weights\",\n",
    "            \"Allocation Flags\",\n",
    "            \"Technical Variables\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"12_OTHER\": {\n",
    "        \"description\": \"Variables that don't fit other categories\",\n",
    "        \"keywords\": [],\n",
    "        \"subcategories\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9954cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5.5: Improved Categorization\n",
      "======================================================================\n",
      "Loading sample (2000 rows)...\n",
      "âœ… Loaded 2000 rows\n",
      "\n",
      "Categorizing variables with improved logic...\n",
      "âœ… Categorization complete!\n",
      "\n",
      "ðŸ“Š CATEGORY DISTRIBUTION:\n",
      "   03_EMPLOYMENT_LABOR: 771 variables (38.6%)\n",
      "   01_DEMOGRAPHICS: 476 variables (23.8%)\n",
      "   11_WEIGHTS_TECHNICAL: 339 variables (17.0%)\n",
      "   02_INCOME_EARNINGS: 158 variables (7.9%)\n",
      "   10_GEOGRAPHY: 104 variables (5.2%)\n",
      "   05_EDUCATION: 102 variables (5.1%)\n",
      "   09_VETERAN_MILITARY: 33 variables (1.7%)\n",
      "   04_HOUSING: 9 variables (0.4%)\n",
      "   07_HEALTH_DISABILITY: 8 variables (0.4%)\n",
      "\n",
      "ðŸ” CHECKING PREVIOUSLY MISCLASSIFIED VARIABLES:\n",
      "======================================================================\n",
      "\n",
      "Variable: AXUNCOV\n",
      "Label: Earnings-union/employee assoc. contract (allocation flag)\n",
      "Category: 11_WEIGHTS_TECHNICAL\n",
      "Matched: flag, allocation\n",
      "\n",
      "Variable: A_AG_NA\n",
      "Label: Indus.&Occ.-agriculture, non-agriculture\n",
      "Category: 03_EMPLOYMENT_LABOR\n",
      "Matched: indus, occ, agriculture, non-agriculture\n",
      "\n",
      "Variable: A_IOELIG\n",
      "Label: Indus.&Occ.-I&O eligibility\n",
      "Category: 03_EMPLOYMENT_LABOR\n",
      "Matched: indus, occ\n",
      "\n",
      "\n",
      "ðŸ“Œ VARIABLES IN '12_OTHER' CATEGORY:\n",
      "======================================================================\n",
      "âœ… No variables in OTHER category!\n",
      "\n",
      "======================================================================\n",
      "END OF STEP 5.5\n",
      "======================================================================\n",
      "\n",
      "âœ… Fixed issues:\n",
      "   1. Added 'indus', 'occ', 'agriculture' to EMPLOYMENT_LABOR\n",
      "   2. Excluded 'allocation' from GEOGRAPHY\n",
      "   3. Added priority system to handle conflicts\n",
      "\n",
      "ðŸ“¤ Please review - are the problem variables fixed?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/Users/kwatchomahinanda/Downloads/census_codebook.csv\"\n",
    "\n",
    "print(\"STEP 5.5: Improved Categorization\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# UPDATED category schema with fixes\n",
    "CATEGORY_SCHEMA = {\n",
    "    \"01_DEMOGRAPHICS\": {\n",
    "        \"keywords\": [\"age\", \"sex\", \"race\", \"ethnicity\", \"hispanic\", \"demographic\", \n",
    "                     \"family\", \"household\", \"relationship\", \"marital\", \"person\"],\n",
    "        \"exclude\": [\"household income\", \"family income\"],\n",
    "        \"priority\": 5  # Medium priority\n",
    "    },\n",
    "    \"02_INCOME_EARNINGS\": {\n",
    "        \"keywords\": [\"income\", \"earnings\", \"wage\", \"salary\", \"pay\", \"revenue\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7  # High priority - specific terms\n",
    "    },\n",
    "    \"03_EMPLOYMENT_LABOR\": {\n",
    "        \"keywords\": [\"employment\", \"labor\", \"work\", \"occupation\", \"industry\", \n",
    "                     \"job\", \"employed\", \"unemployed\", \"worker\", \"class of worker\",\n",
    "                     \"hours worked\", \"full-time\", \"part-time\", \"indus\", \"occ\",\n",
    "                     \"agriculture\", \"non-agriculture\"],  # ADDED: indus, occ, agriculture\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 6  # High priority\n",
    "    },\n",
    "    \"04_HOUSING\": {\n",
    "        \"keywords\": [\"housing\", \"house\", \"rent\", \"mortgage\", \"property\", \n",
    "                     \"dwelling\", \"residence\", \"apartment\", \"owner\", \"renter\",\n",
    "                     \"real estate\", \"home\"],\n",
    "        \"exclude\": [\"household\"],\n",
    "        \"priority\": 7  # High priority - specific terms\n",
    "    },\n",
    "    \"05_EDUCATION\": {\n",
    "        \"keywords\": [\"education\", \"school\", \"enrollment\", \"degree\", \"college\", \n",
    "                     \"university\", \"grade\", \"attainment\", \"diploma\", \"student\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7  # High priority - specific terms\n",
    "    },\n",
    "    \"06_POVERTY_ASSISTANCE\": {\n",
    "        \"keywords\": [\"poverty\", \"poor\", \"assistance\", \"welfare\", \"tanf\", \n",
    "                     \"snap\", \"food stamp\", \"medicaid\", \"ssi\", \"general assist\",\n",
    "                     \"public assistance\", \"government program\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 8  # Highest priority - very specific\n",
    "    },\n",
    "    \"07_HEALTH_DISABILITY\": {\n",
    "        \"keywords\": [\"health\", \"insurance\", \"disability\", \"medical\", \"medicare\", \n",
    "                     \"coverage\", \"doctor\", \"dentist\", \"hospital\", \"disabled\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7  # High priority\n",
    "    },\n",
    "    \"08_ASSETS_WEALTH\": {\n",
    "        \"keywords\": [\"asset\", \"saving\", \"stock\", \"investment\", \"account\", \n",
    "                     \"fund\", \"bond\", \"debt\", \"owe\", \"equity\", \"wealth\",\n",
    "                     \"bank\", \"financial\", \"dividend\", \"interest\", \"margin\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 6  # Medium-high priority\n",
    "    },\n",
    "    \"09_VETERAN_MILITARY\": {\n",
    "        \"keywords\": [\"veteran\", \"military\", \"service\", \"armed forces\", \n",
    "                     \"va\", \"retirement pay\", \"army\", \"navy\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7  # High priority - specific\n",
    "    },\n",
    "    \"10_GEOGRAPHY\": {\n",
    "        \"keywords\": [\"geography\", \"fips\", \"state\", \"county\", \"tract\", \n",
    "                     \"location\", \"msa\", \"cbsa\", \"region\", \"place\", \"cmsa\",\n",
    "                     \"metropolitan\", \"central city\"],  # More specific geo terms\n",
    "        \"exclude\": [\"allocation\"],  # ADDED: Don't catch allocation flags\n",
    "        \"priority\": 6  # Medium-high priority\n",
    "    },\n",
    "    \"11_WEIGHTS_TECHNICAL\": {\n",
    "        \"keywords\": [\"weight\", \"flag\", \"allocation\", \"imputation\", \"recode\", \n",
    "                     \"check item\", \"interviewer\", \"topcode\", \"edit\", \"final weight\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 4  # Lower priority - catch-all for technical stuff\n",
    "    }\n",
    "}\n",
    "\n",
    "def categorize_variable_improved(label, variable_code):\n",
    "    \"\"\"\n",
    "    Improved categorization with priority system\n",
    "    \"\"\"\n",
    "    if pd.isna(label):\n",
    "        return \"12_OTHER\", 0.0, \"No label\"\n",
    "    \n",
    "    label_lower = str(label).lower()\n",
    "    \n",
    "    # Check each category\n",
    "    category_matches = {}\n",
    "    \n",
    "    for category, info in CATEGORY_SCHEMA.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Check for excluded keywords first\n",
    "        excluded = False\n",
    "        for exclude_word in info[\"exclude\"]:\n",
    "            if exclude_word in label_lower:\n",
    "                excluded = True\n",
    "                break\n",
    "        \n",
    "        if excluded:\n",
    "            continue\n",
    "        \n",
    "        # Count matching keywords\n",
    "        for keyword in info[\"keywords\"]:\n",
    "            if keyword in label_lower:\n",
    "                score += 1\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if score > 0:\n",
    "            # Weighted score = matches * priority\n",
    "            weighted_score = score * info[\"priority\"]\n",
    "            category_matches[category] = {\n",
    "                \"score\": score,\n",
    "                \"weighted_score\": weighted_score,\n",
    "                \"keywords\": matched_keywords\n",
    "            }\n",
    "    \n",
    "    # Return category with highest weighted score\n",
    "    if category_matches:\n",
    "        best_category = max(category_matches, key=lambda x: category_matches[x][\"weighted_score\"])\n",
    "        best_info = category_matches[best_category]\n",
    "        return best_category, best_info[\"score\"], \", \".join(best_info[\"keywords\"])\n",
    "    else:\n",
    "        return \"12_OTHER\", 0.0, \"No matches\"\n",
    "\n",
    "# Test on sample\n",
    "print(\"Loading sample (2000 rows)...\")\n",
    "df_sample = pd.read_csv(file_path, nrows=2000)\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_sample)} rows\\n\")\n",
    "\n",
    "# Categorize with improved function\n",
    "print(\"Categorizing variables with improved logic...\")\n",
    "results = df_sample.apply(\n",
    "    lambda row: categorize_variable_improved(row['label'], row['variable']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_sample['category'] = results.apply(lambda x: x[0])\n",
    "df_sample['category_confidence'] = results.apply(lambda x: x[1])\n",
    "df_sample['matched_keywords'] = results.apply(lambda x: x[2])\n",
    "\n",
    "print(\"âœ… Categorization complete!\\n\")\n",
    "\n",
    "# Show distribution\n",
    "print(\"ðŸ“Š CATEGORY DISTRIBUTION:\")\n",
    "category_counts = df_sample['category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(df_sample)) * 100\n",
    "    print(f\"   {category}: {count} variables ({percentage:.1f}%)\")\n",
    "\n",
    "# Check our problem cases\n",
    "print(f\"\\nðŸ” CHECKING PREVIOUSLY MISCLASSIFIED VARIABLES:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "problem_vars = ['AXUNCOV', 'A_AG_NA', 'A_IOELIG']\n",
    "for var in problem_vars:\n",
    "    if var in df_sample['variable'].values:\n",
    "        row = df_sample[df_sample['variable'] == var].iloc[0]\n",
    "        print(f\"\\nVariable: {row['variable']}\")\n",
    "        print(f\"Label: {row['label']}\")\n",
    "        print(f\"Category: {row['category']}\")\n",
    "        print(f\"Matched: {row['matched_keywords']}\")\n",
    "\n",
    "# Show 12_OTHER category\n",
    "print(f\"\\n\\nðŸ“Œ VARIABLES IN '12_OTHER' CATEGORY:\")\n",
    "print(\"=\"*70)\n",
    "other_vars = df_sample[df_sample['category'] == '12_OTHER'][['variable', 'label']].head(15)\n",
    "if len(other_vars) > 0:\n",
    "    for idx, row in other_vars.iterrows():\n",
    "        print(f\"\\nVariable: {row['variable']}\")\n",
    "        print(f\"Label: {row['label']}\")\n",
    "else:\n",
    "    print(\"âœ… No variables in OTHER category!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF STEP 5.5\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nâœ… Fixed issues:\")\n",
    "print(\"   1. Added 'indus', 'occ', 'agriculture' to EMPLOYMENT_LABOR\")\n",
    "print(\"   2. Excluded 'allocation' from GEOGRAPHY\")\n",
    "print(\"   3. Added priority system to handle conflicts\")\n",
    "print(\"\\nðŸ“¤ Please review - are the problem variables fixed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28264ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 6: Processing Full Dataset (584,888 rows)\n",
      "======================================================================\n",
      "This will take 10-20 minutes - be patient!\n",
      "======================================================================\n",
      "\n",
      "Reading file in chunks of 50,000 rows...\n",
      "Will save results to: census_codebook_categorized.csv\n",
      "\n",
      "Chunk 1: Processed 50,000 rows in 1.0s\n",
      "   Total so far: 50,000 rows | Elapsed: 0.0 min\n",
      "\n",
      "Chunk 2: Processed 50,000 rows in 1.1s\n",
      "   Total so far: 100,000 rows | Elapsed: 0.0 min\n",
      "\n",
      "Chunk 3: Processed 50,000 rows in 1.0s\n",
      "   Total so far: 150,000 rows | Elapsed: 0.1 min\n",
      "\n",
      "Chunk 4: Processed 50,000 rows in 1.0s\n",
      "   Total so far: 200,000 rows | Elapsed: 0.1 min\n",
      "\n",
      "Chunk 5: Processed 50,000 rows in 1.0s\n",
      "   Total so far: 250,000 rows | Elapsed: 0.1 min\n",
      "\n",
      "Chunk 6: Processed 50,000 rows in 1.0s\n",
      "   Total so far: 300,000 rows | Elapsed: 0.1 min\n",
      "\n",
      "Chunk 7: Processed 50,000 rows in 1.4s\n",
      "   Total so far: 350,000 rows | Elapsed: 0.1 min\n",
      "\n",
      "Chunk 8: Processed 50,000 rows in 1.0s\n",
      "   Total so far: 400,000 rows | Elapsed: 0.2 min\n",
      "\n",
      "Chunk 9: Processed 50,000 rows in 1.1s\n",
      "   Total so far: 450,000 rows | Elapsed: 0.2 min\n",
      "\n",
      "Chunk 10: Processed 46,956 rows in 0.9s\n",
      "   Total so far: 500,000 rows | Elapsed: 0.2 min\n",
      "\n",
      "======================================================================\n",
      "PROCESSING COMPLETE\n",
      "======================================================================\n",
      "Total time: 0.2 minutes\n",
      "Saved to: census_codebook_categorized.csv\n",
      "\n",
      "Loading final results for analysis...\n",
      "\n",
      "FINAL CATEGORY DISTRIBUTION:\n",
      "   11_WEIGHTS_TECHNICAL: 122,833 variables (24.7%)\n",
      "   03_EMPLOYMENT_LABOR: 120,118 variables (24.2%)\n",
      "   12_OTHER: 63,030 variables (12.7%)\n",
      "   01_DEMOGRAPHICS: 58,677 variables (11.8%)\n",
      "   02_INCOME_EARNINGS: 33,928 variables (6.8%)\n",
      "   04_HOUSING: 22,565 variables (4.5%)\n",
      "   06_POVERTY_ASSISTANCE: 16,236 variables (3.3%)\n",
      "   10_GEOGRAPHY: 13,794 variables (2.8%)\n",
      "   07_HEALTH_DISABILITY: 13,484 variables (2.7%)\n",
      "   05_EDUCATION: 12,368 variables (2.5%)\n",
      "   09_VETERAN_MILITARY: 12,210 variables (2.5%)\n",
      "   08_ASSETS_WEALTH: 7,713 variables (1.6%)\n",
      "\n",
      "Total variables categorized: 496,956\n",
      "File saved: census_codebook_categorized.csv\n",
      "\n",
      "======================================================================\n",
      "END OF STEP 6\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "file_path = \"/Users/kwatchomahinanda/Downloads/census_codebook.csv\"\n",
    "\n",
    "print(\"STEP 6: Processing Full Dataset (584,888 rows)\")\n",
    "print(\"=\"*70)\n",
    "print(\"This will take 10-20 minutes - be patient!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Same improved category schema\n",
    "CATEGORY_SCHEMA = {\n",
    "    \"01_DEMOGRAPHICS\": {\n",
    "        \"keywords\": [\"age\", \"sex\", \"race\", \"ethnicity\", \"hispanic\", \"demographic\", \n",
    "                     \"family\", \"household\", \"relationship\", \"marital\", \"person\"],\n",
    "        \"exclude\": [\"household income\", \"family income\"],\n",
    "        \"priority\": 5\n",
    "    },\n",
    "    \"02_INCOME_EARNINGS\": {\n",
    "        \"keywords\": [\"income\", \"earnings\", \"wage\", \"salary\", \"pay\", \"revenue\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"03_EMPLOYMENT_LABOR\": {\n",
    "        \"keywords\": [\"employment\", \"labor\", \"work\", \"occupation\", \"industry\", \n",
    "                     \"job\", \"employed\", \"unemployed\", \"worker\", \"class of worker\",\n",
    "                     \"hours worked\", \"full-time\", \"part-time\", \"indus\", \"occ\",\n",
    "                     \"agriculture\", \"non-agriculture\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 6\n",
    "    },\n",
    "    \"04_HOUSING\": {\n",
    "        \"keywords\": [\"housing\", \"house\", \"rent\", \"mortgage\", \"property\", \n",
    "                     \"dwelling\", \"residence\", \"apartment\", \"owner\", \"renter\",\n",
    "                     \"real estate\", \"home\"],\n",
    "        \"exclude\": [\"household\"],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"05_EDUCATION\": {\n",
    "        \"keywords\": [\"education\", \"school\", \"enrollment\", \"degree\", \"college\", \n",
    "                     \"university\", \"grade\", \"attainment\", \"diploma\", \"student\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"06_POVERTY_ASSISTANCE\": {\n",
    "        \"keywords\": [\"poverty\", \"poor\", \"assistance\", \"welfare\", \"tanf\", \n",
    "                     \"snap\", \"food stamp\", \"medicaid\", \"ssi\", \"general assist\",\n",
    "                     \"public assistance\", \"government program\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 8\n",
    "    },\n",
    "    \"07_HEALTH_DISABILITY\": {\n",
    "        \"keywords\": [\"health\", \"insurance\", \"disability\", \"medical\", \"medicare\", \n",
    "                     \"coverage\", \"doctor\", \"dentist\", \"hospital\", \"disabled\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"08_ASSETS_WEALTH\": {\n",
    "        \"keywords\": [\"asset\", \"saving\", \"stock\", \"investment\", \"account\", \n",
    "                     \"fund\", \"bond\", \"debt\", \"owe\", \"equity\", \"wealth\",\n",
    "                     \"bank\", \"financial\", \"dividend\", \"interest\", \"margin\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 6\n",
    "    },\n",
    "    \"09_VETERAN_MILITARY\": {\n",
    "        \"keywords\": [\"veteran\", \"military\", \"service\", \"armed forces\", \n",
    "                     \"va\", \"retirement pay\", \"army\", \"navy\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"10_GEOGRAPHY\": {\n",
    "        \"keywords\": [\"geography\", \"fips\", \"state\", \"county\", \"tract\", \n",
    "                     \"location\", \"msa\", \"cbsa\", \"region\", \"place\", \"cmsa\",\n",
    "                     \"metropolitan\", \"central city\"],\n",
    "        \"exclude\": [\"allocation\"],\n",
    "        \"priority\": 6\n",
    "    },\n",
    "    \"11_WEIGHTS_TECHNICAL\": {\n",
    "        \"keywords\": [\"weight\", \"flag\", \"allocation\", \"imputation\", \"recode\", \n",
    "                     \"check item\", \"interviewer\", \"topcode\", \"edit\", \"final weight\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "def categorize_variable_improved(label, variable_code):\n",
    "    \"\"\"Categorization function with priority system\"\"\"\n",
    "    if pd.isna(label):\n",
    "        return \"12_OTHER\", 0.0, \"No label\"\n",
    "    \n",
    "    label_lower = str(label).lower()\n",
    "    category_matches = {}\n",
    "    \n",
    "    for category, info in CATEGORY_SCHEMA.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        excluded = False\n",
    "        for exclude_word in info[\"exclude\"]:\n",
    "            if exclude_word in label_lower:\n",
    "                excluded = True\n",
    "                break\n",
    "        \n",
    "        if excluded:\n",
    "            continue\n",
    "        \n",
    "        for keyword in info[\"keywords\"]:\n",
    "            if keyword in label_lower:\n",
    "                score += 1\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if score > 0:\n",
    "            weighted_score = score * info[\"priority\"]\n",
    "            category_matches[category] = {\n",
    "                \"score\": score,\n",
    "                \"weighted_score\": weighted_score,\n",
    "                \"keywords\": matched_keywords\n",
    "            }\n",
    "    \n",
    "    if category_matches:\n",
    "        best_category = max(category_matches, key=lambda x: category_matches[x][\"weighted_score\"])\n",
    "        best_info = category_matches[best_category]\n",
    "        return best_category, best_info[\"score\"], \", \".join(best_info[\"keywords\"])\n",
    "    else:\n",
    "        return \"12_OTHER\", 0.0, \"No matches\"\n",
    "\n",
    "# Process in chunks to track progress\n",
    "chunk_size = 50000\n",
    "output_file = \"census_codebook_categorized.csv\"\n",
    "\n",
    "print(f\"\\nReading file in chunks of {chunk_size:,} rows...\")\n",
    "print(f\"Will save results to: {output_file}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "first_chunk = True\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    chunk_start = time.time()\n",
    "    \n",
    "    # Categorize\n",
    "    results = chunk.apply(\n",
    "        lambda row: categorize_variable_improved(row['label'], row['variable']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    chunk['category'] = results.apply(lambda x: x[0])\n",
    "    chunk['category_confidence'] = results.apply(lambda x: x[1])\n",
    "    chunk['matched_keywords'] = results.apply(lambda x: x[2])\n",
    "    \n",
    "    # Save to CSV\n",
    "    if first_chunk:\n",
    "        chunk.to_csv(output_file, index=False, mode='w')\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        chunk.to_csv(output_file, index=False, mode='a', header=False)\n",
    "    \n",
    "    chunk_time = time.time() - chunk_start\n",
    "    rows_processed = (i + 1) * chunk_size\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Chunk {i+1}: Processed {len(chunk):,} rows in {chunk_time:.1f}s\")\n",
    "    print(f\"   Total so far: {rows_processed:,} rows | Elapsed: {elapsed/60:.1f} min\")\n",
    "    print()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total time: {total_time/60:.1f} minutes\")\n",
    "print(f\"Saved to: {output_file}\")\n",
    "\n",
    "# Load and analyze final results\n",
    "print(f\"\\nLoading final results for analysis...\")\n",
    "df_final = pd.read_csv(output_file)\n",
    "\n",
    "print(f\"\\nFINAL CATEGORY DISTRIBUTION:\")\n",
    "category_counts = df_final['category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(df_final)) * 100\n",
    "    print(f\"   {category}: {count:,} variables ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotal variables categorized: {len(df_final):,}\")\n",
    "print(f\"File saved: {output_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF STEP 6\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3419fc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 7: Investigating OTHER Category\n",
      "======================================================================\n",
      "Total in OTHER category: 63,030\n",
      "Percentage of total: 12.7%\n",
      "\n",
      "Random sample of 50 variables from OTHER category:\n",
      "======================================================================\n",
      "\n",
      "Variable: TM9385\n",
      "Label: Are the Names of Any Emp.s Listed for th\n",
      "Survey: Wave 8 Survey of Income and Program Participation - 1992 Pan...\n",
      "\n",
      "Variable: IO10003\n",
      "Label: Imp. Own Int. 100-103\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 1992 Pan...\n",
      "\n",
      "Variable: ISE22322\n",
      "Label: Imp. Proprietorship/Partnership\n",
      "Survey: Wave 8 Survey of Income and Program Participation - 1990 Pan...\n",
      "\n",
      "Variable: T39AMT\n",
      "Label: GI: Amount of pension/retirement lump sums (ISS Code 39)\n",
      "Survey: Wave 1 Survey of Income and Program Participation - 2004 Pan...\n",
      "\n",
      "Variable: TM7566\n",
      "Label: TM7566\n",
      "Survey: Wave 9 Survey of Income and Program Participation - 1992 Pan...\n",
      "\n",
      "Variable: EASST01\n",
      "Label: ED: Federal Pell Grant\n",
      "Survey: Wave 12 Survey of Income and Program Participation - 1996 Pa...\n",
      "\n",
      "Variable: RWS1\n",
      "Label: GI: Reason for stopping WIC the first time\n",
      "Survey: Wave 8 Survey of Income and Program Participation - 2008 Pan...\n",
      "\n",
      "Variable: TM9590\n",
      "Label: TM9590\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 1993 Pan...\n",
      "\n",
      "Variable: HESP8\n",
      "Label: Program - foods received from WIC Program, past 30 days\n",
      "Survey: Dec 2017 Current Population Survey: Food Security Supplement...\n",
      "\n",
      "Variable: PESNETH\n",
      "Label: Internet use this year, news/weather/sports - y/n\n",
      "Survey: Sep 2001 Current Population Survey: Computer and Internet Us...\n",
      "\n",
      "Variable: ER12\n",
      "Label: GI: Receipt of Employer/Union Temp. Sickness Benefits\n",
      "Survey: Wave 9 Survey of Income and Program Participation - 2001 Pan...\n",
      "\n",
      "Variable: ECHCOV06\n",
      "Label: HB: Reason sixth child was not covered\n",
      "Survey: Wave 5 Survey of Income and Program Participation - 2004 Pan...\n",
      "\n",
      "Variable: TM8070\n",
      "Label: If I Were to Call Back Later Would You B\n",
      "Survey: Wave 7 Survey of Income and Program Participation - 1990 Pan...\n",
      "\n",
      "Variable: AJB7_AWOP1\n",
      "Label: Suppressed\n",
      "Survey: 2024 Survey of Income and Program Participation (SIPP)...\n",
      "\n",
      "Variable: ERENDB1\n",
      "Label: BS: Reason business ended\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 2008 Pan...\n",
      "\n",
      "Variable: PECERT1\n",
      "Label: Certification Active\n",
      "Survey: Current Population Survey: Basic Monthly...\n",
      "\n",
      "Variable: AJB5_PTRESN3\n",
      "Label: Suppressed\n",
      "Survey: 2023 Survey of Income and Program Participation (SIPP)...\n",
      "\n",
      "Variable: TM7551\n",
      "Label: TM7551\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 1993 Pan...\n",
      "\n",
      "Variable: PED6B\n",
      "Label: More or less than a week stopped smoking\n",
      "Survey: Jul 2014 Current Population Survey: Tobacco Use Supplement...\n",
      "\n",
      "Variable: PEH8B\n",
      "Label: Smoked 30 minutes of awakening\n",
      "Survey: Jan 2015 Current Population Survey: Tobacco Use Supplement...\n",
      "\n",
      "Variable: IPLUS\n",
      "Label: Imp. SC1686 PLUS\n",
      "Survey: Wave 3 Survey of Income and Program Participation - 1992 Pan...\n",
      "\n",
      "Variable: TM8788\n",
      "Label: Chk. Item T47 Write the Pers. No. of the\n",
      "Survey: Wave 2 Survey of Income and Program Participation - 1991 Pan...\n",
      "\n",
      "Variable: ERELHR1I\n",
      "Label: CC: Hours the relative cared for the 4th YOUNGEST child\n",
      "Survey: Wave 4 Survey of Income and Program Participation - 1996 Pan...\n",
      "\n",
      "Variable: ECKD08G\n",
      "Label: CC: Arrangement of child or day care center\n",
      "Survey: Wave 8 Survey of Income and Program Participation - 2004 Pan...\n",
      "\n",
      "Variable: HESHM1\n",
      "Label: Scale30 - child not eating enough, past 30 days\n",
      "Survey: Dec 2014 Current Population Survey: Food Security Supplement...\n",
      "\n",
      "Variable: TM9634\n",
      "Label: Percent of Total Ed. Asst. Rec. During t\n",
      "Survey: Wave 8 Survey of Income and Program Participation - 1993 Pan...\n",
      "\n",
      "Variable: MLPD\n",
      "Label: Active duty -- MAY1975 to AUG1980\n",
      "Survey: 2004 American Community Survey: 1-Year Estimates - Public Us...\n",
      "\n",
      "Variable: T42AMT\n",
      "Label: GI: Amount of draw from an IRA/Keough/401k or Thrift Plan\n",
      "Survey: Wave 7 Survey of Income and Program Participation - 2001 Pan...\n",
      "\n",
      "Variable: ID\n",
      "Label: ID\n",
      "Survey: Wave 8 Survey of Income and Program Participation - 1991 Pan...\n",
      "\n",
      "Variable: RWB2R2\n",
      "Label: GI: Second reason for applying for WIC the 2nd time\n",
      "Survey: Wave 7 Survey of Income and Program Participation - 2008 Pan...\n",
      "\n",
      "Variable: IM8902\n",
      "Label: Imp. of Tm8902\n",
      "Survey: Wave 3 Survey of Income and Program Participation - 1993 Pan...\n",
      "\n",
      "Variable: EDCER104\n",
      "Label: CS: Signature on birth certificate\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 2008 Pan...\n",
      "\n",
      "Variable: S23AMT\n",
      "Label: Foster Child Care Pmts.\n",
      "Survey: Wave 5 Survey of Income and Program Participation - 1993 Pan...\n",
      "\n",
      "Variable: SE12226\n",
      "Label: Partners in Bus., Per. No.s\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 1993 Pan...\n",
      "\n",
      "Variable: EVBNO1\n",
      "Label: BU: First Business number\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 1996 Pan...\n",
      "\n",
      "Variable: PELNDAD\n",
      "Label: Line Number of Father\n",
      "Survey: Jun 2012 Current Population Survey: Basic Monthly...\n",
      "\n",
      "Variable: EASST05\n",
      "Label: ED: Loan that has to be repaid (Stafford, Perkins, SLS)\n",
      "Survey: Wave 3 Survey of Income and Program Participation - 1996 Pan...\n",
      "\n",
      "Variable: IMP8200\n",
      "Label: IMP8200\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 1993 Pan...\n",
      "\n",
      "Variable: RWB1R1\n",
      "Label: GI: First reason for applying for WIC the 1st time\n",
      "Survey: Wave 6 Survey of Income and Program Participation - 2004 Pan...\n",
      "\n",
      "Variable: HESSHF1A\n",
      "Label: Scale12 - usual number of days adults did not eat whole day\n",
      "Survey: Apr 2001 Current Population Survey: Food Security Supplement...\n",
      "\n",
      "Variable: TM9538\n",
      "Label: TM9538\n",
      "Survey: Wave 9 Survey of Income and Program Participation - 1992 Pan...\n",
      "\n",
      "Variable: PNSP\n",
      "Label: Spouse Per. No.\n",
      "Survey: Wave 7 Survey of Income and Program Participation - 1991 Pan...\n",
      "\n",
      "Variable: EPAYOTHC\n",
      "Label: CC: Paid non-relative to care for the 3rd YOUNGEST child\n",
      "Survey: Wave 10 Survey of Income and Program Participation - 1996 Pa...\n",
      "\n",
      "Variable: R23\n",
      "Label: Foster Child Care Pmts. Recip.\n",
      "Survey: Wave 3 Survey of Income and Program Participation - 1991 Pan...\n",
      "\n",
      "Variable: TM9338\n",
      "Label: TM9338\n",
      "Survey: Wave 9 Survey of Income and Program Participation - 1992 Pan...\n",
      "\n",
      "Variable: EGVJT\n",
      "Label: AS: Jointly owned U.S. Government securities\n",
      "Survey: Wave 5 Survey of Income and Program Participation - 2001 Pan...\n",
      "\n",
      "Variable: IMP6086\n",
      "Label: IMP6086\n",
      "Survey: Wave 9 Survey of Income and Program Participation - 1993 Pan...\n",
      "\n",
      "Variable: EPAYHR2\n",
      "Label: JB: Paid by the hour\n",
      "Survey: Wave 12 Survey of Income and Program Participation - 2008 Pa...\n",
      "\n",
      "Variable: EHIRSN01\n",
      "Label: HI: Reason not covered: too expensive, can't afford\n",
      "Survey: Wave 15 Survey of Income and Program Participation - 2008 Pa...\n",
      "\n",
      "Variable: YYYYMM\n",
      "Label: Year-Month\n",
      "Survey: Current Population Survey: Veterans Supplement...\n",
      "\n",
      "\n",
      "Pattern Analysis:\n",
      "======================================================================\n",
      "\n",
      "Top 30 most common words in OTHER category labels:\n",
      "   of: 14815\n",
      "   for: 5804\n",
      "   -: 5286\n",
      "   or: 4994\n",
      "   the: 4704\n",
      "   imp.: 4652\n",
      "   child: 4141\n",
      "   gi:: 3886\n",
      "   to: 3593\n",
      "   in: 3535\n",
      "   reason: 3077\n",
      "   number: 2728\n",
      "   suppressed: 2523\n",
      "   from: 2256\n",
      "   other: 2222\n",
      "   cc:: 2187\n",
      "   past: 1973\n",
      "   type: 1900\n",
      "   a: 1895\n",
      "   recip.: 1870\n",
      "   code: 1836\n",
      "   time: 1825\n",
      "   youngest: 1705\n",
      "   amount: 1667\n",
      "   receipt: 1620\n",
      "   cs:: 1596\n",
      "   inc.: 1574\n",
      "   month: 1541\n",
      "   by: 1496\n",
      "   bs:: 1488\n",
      "\n",
      "\n",
      "Survey distribution in OTHER category:\n",
      "   Wave 6 Survey of Income and Program Participation - 1993 Panel: Topica... : 2882\n",
      "   Wave 9 Survey of Income and Program Participation - 1992 Panel: Topica... : 2881\n",
      "   Wave 9 Survey of Income and Program Participation - 1993 Panel: Topica... : 2160\n",
      "   Current Population Survey: Tobacco Use Supplement... : 1198\n",
      "   2023 Survey of Income and Program Participation (SIPP)... : 1124\n",
      "   2024 Survey of Income and Program Participation (SIPP)... : 1072\n",
      "   2022 Survey of Income and Program Participation... : 983\n",
      "   Wave 5 Survey of Income and Program Participation - 2004 Panel: Topica... : 587\n",
      "   Wave 6 Survey of Income and Program Participation - 2008 Panel: Topica... : 573\n",
      "   Wave 3 Survey of Income and Program Participation - 1991 Panel: Topica... : 569\n",
      "\n",
      "======================================================================\n",
      "END OF STEP 7\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categorized_file = \"census_codebook_categorized.csv\"\n",
    "\n",
    "print(\"STEP 7: Investigating OTHER Category\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load the categorized data\n",
    "df = pd.read_csv(categorized_file)\n",
    "\n",
    "# Filter to OTHER category\n",
    "df_other = df[df['category'] == '12_OTHER']\n",
    "\n",
    "print(f\"Total in OTHER category: {len(df_other):,}\")\n",
    "print(f\"Percentage of total: {(len(df_other)/len(df))*100:.1f}%\")\n",
    "\n",
    "# Sample 50 random examples\n",
    "print(f\"\\nRandom sample of 50 variables from OTHER category:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sample = df_other.sample(min(50, len(df_other)), random_state=42)\n",
    "for i, row in sample.iterrows():\n",
    "    print(f\"\\nVariable: {row['variable']}\")\n",
    "    print(f\"Label: {row['label']}\")\n",
    "    print(f\"Survey: {row['title'][:60]}...\")\n",
    "\n",
    "# Analyze patterns in OTHER\n",
    "print(\"\\n\\nPattern Analysis:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check for common words\n",
    "from collections import Counter\n",
    "all_labels = ' '.join(df_other['label'].dropna().astype(str).str.lower()).split()\n",
    "word_counts = Counter(all_labels)\n",
    "\n",
    "print(\"\\nTop 30 most common words in OTHER category labels:\")\n",
    "for word, count in word_counts.most_common(30):\n",
    "    print(f\"   {word}: {count}\")\n",
    "\n",
    "# Check survey titles\n",
    "print(\"\\n\\nSurvey distribution in OTHER category:\")\n",
    "survey_counts = df_other['title'].value_counts().head(10)\n",
    "for survey, count in survey_counts.items():\n",
    "    print(f\"   {survey[:70]}... : {count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF STEP 7\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1994ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Census Codebook Categorization Script\n",
    "--------------------------------------\n",
    "This script categorizes Census variables into 12 thematic categories\n",
    "for easier retrieval in the Invest Atlanta RAG system.\n",
    "\n",
    "Input: census_codebook.csv (raw Census variable codebook)\n",
    "Output: census_codebook_categorized.csv (codebook with category assignments)\n",
    "\n",
    "Author: Kwatcho Mahinanda\n",
    "Date: January 2026\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# CONFIGURATION\n",
    "\n",
    "INPUT_FILE = \"/Users/kwatchomahinanda/Downloads/census_codebook.csv\"\n",
    "OUTPUT_FILE = \"census_codebook_categorized.csv\"\n",
    "CHUNK_SIZE = 50000  # Process in chunks to manage memory\n",
    "\n",
    "# CATEGORY SCHEMA\n",
    "\n",
    "# Each category has:\n",
    "# - keywords: terms that indicate this category\n",
    "# - exclude: terms that disqualify a match\n",
    "# - priority: higher priority wins in case of conflicts (1-10 scale)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CATEGORY_SCHEMA = {\n",
    "    \"01_DEMOGRAPHICS\": {\n",
    "        \"keywords\": [\"age\", \"sex\", \"race\", \"ethnicity\", \"hispanic\", \"demographic\", \n",
    "                     \"family\", \"household\", \"relationship\", \"marital\", \"person\"],\n",
    "        \"exclude\": [\"household income\", \"family income\"],\n",
    "        \"priority\": 5\n",
    "    },\n",
    "    \"02_INCOME_EARNINGS\": {\n",
    "        \"keywords\": [\"income\", \"earnings\", \"wage\", \"salary\", \"pay\", \"revenue\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"03_EMPLOYMENT_LABOR\": {\n",
    "        \"keywords\": [\"employment\", \"labor\", \"work\", \"occupation\", \"industry\", \n",
    "                     \"job\", \"employed\", \"unemployed\", \"worker\", \"class of worker\",\n",
    "                     \"hours worked\", \"full-time\", \"part-time\", \"indus\", \"occ\",\n",
    "                     \"agriculture\", \"non-agriculture\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 6\n",
    "    },\n",
    "    \"04_HOUSING\": {\n",
    "        \"keywords\": [\"housing\", \"house\", \"rent\", \"mortgage\", \"property\", \n",
    "                     \"dwelling\", \"residence\", \"apartment\", \"owner\", \"renter\",\n",
    "                     \"real estate\", \"home\"],\n",
    "        \"exclude\": [\"household\"],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"05_EDUCATION\": {\n",
    "        \"keywords\": [\"education\", \"school\", \"enrollment\", \"degree\", \"college\", \n",
    "                     \"university\", \"grade\", \"attainment\", \"diploma\", \"student\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"06_POVERTY_ASSISTANCE\": {\n",
    "        \"keywords\": [\"poverty\", \"poor\", \"assistance\", \"welfare\", \"tanf\", \n",
    "                     \"snap\", \"food stamp\", \"medicaid\", \"ssi\", \"general assist\",\n",
    "                     \"public assistance\", \"government program\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 8\n",
    "    },\n",
    "    \"07_HEALTH_DISABILITY\": {\n",
    "        \"keywords\": [\"health\", \"insurance\", \"disability\", \"medical\", \"medicare\", \n",
    "                     \"coverage\", \"doctor\", \"dentist\", \"hospital\", \"disabled\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"08_ASSETS_WEALTH\": {\n",
    "        \"keywords\": [\"asset\", \"saving\", \"stock\", \"investment\", \"account\", \n",
    "                     \"fund\", \"bond\", \"debt\", \"owe\", \"equity\", \"wealth\",\n",
    "                     \"bank\", \"financial\", \"dividend\", \"interest\", \"margin\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 6\n",
    "    },\n",
    "    \"09_VETERAN_MILITARY\": {\n",
    "        \"keywords\": [\"veteran\", \"military\", \"service\", \"armed forces\", \n",
    "                     \"va\", \"retirement pay\", \"army\", \"navy\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 7\n",
    "    },\n",
    "    \"10_GEOGRAPHY\": {\n",
    "        \"keywords\": [\"geography\", \"fips\", \"state\", \"county\", \"tract\", \n",
    "                     \"location\", \"msa\", \"cbsa\", \"region\", \"place\", \"cmsa\",\n",
    "                     \"metropolitan\", \"central city\"],\n",
    "        \"exclude\": [\"allocation\"],\n",
    "        \"priority\": 6\n",
    "    },\n",
    "    \"11_WEIGHTS_TECHNICAL\": {\n",
    "        \"keywords\": [\"weight\", \"flag\", \"allocation\", \"imputation\", \"recode\", \n",
    "                     \"check item\", \"interviewer\", \"topcode\", \"edit\", \"final weight\"],\n",
    "        \"exclude\": [],\n",
    "        \"priority\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# CATEGORIZATION FUNCTION\n",
    "# ==============================================================================\n",
    "\n",
    "def categorize_variable(label, variable_code):\n",
    "    \"\"\"\n",
    "    Assign a category to a Census variable based on its label.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    label : str\n",
    "        The human-readable description of the variable\n",
    "    variable_code : str\n",
    "        The variable code (e.g., 'B19013_001E')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (category, confidence_score, matched_keywords)\n",
    "        - category: assigned category (e.g., '01_DEMOGRAPHICS')\n",
    "        - confidence_score: number of keywords matched\n",
    "        - matched_keywords: comma-separated list of matched terms\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle missing labels\n",
    "    if pd.isna(label):\n",
    "        return \"12_OTHER\", 0.0, \"No label\"\n",
    "    \n",
    "    label_lower = str(label).lower()\n",
    "    category_matches = {}\n",
    "    \n",
    "    # Evaluate each category\n",
    "    for category, info in CATEGORY_SCHEMA.items():\n",
    "        score = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        # Check if any exclude terms disqualify this category\n",
    "        excluded = False\n",
    "        for exclude_word in info[\"exclude\"]:\n",
    "            if exclude_word in label_lower:\n",
    "                excluded = True\n",
    "                break\n",
    "        \n",
    "        if excluded:\n",
    "            continue\n",
    "        \n",
    "        # Count matching keywords\n",
    "        for keyword in info[\"keywords\"]:\n",
    "            if keyword in label_lower:\n",
    "                score += 1\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        # If keywords matched, calculate weighted score\n",
    "        if score > 0:\n",
    "            weighted_score = score * info[\"priority\"]\n",
    "            category_matches[category] = {\n",
    "                \"score\": score,\n",
    "                \"weighted_score\": weighted_score,\n",
    "                \"keywords\": matched_keywords\n",
    "            }\n",
    "    \n",
    "    # Return category with highest weighted score\n",
    "    if category_matches:\n",
    "        best_category = max(category_matches, \n",
    "                          key=lambda x: category_matches[x][\"weighted_score\"])\n",
    "        best_info = category_matches[best_category]\n",
    "        return best_category, best_info[\"score\"], \", \".join(best_info[\"keywords\"])\n",
    "    else:\n",
    "        return \"12_OTHER\", 0.0, \"No matches\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to categorize Census variables and save results.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"Census Codebook Categorization\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Input file: {INPUT_FILE}\")\n",
    "    print(f\"Output file: {OUTPUT_FILE}\")\n",
    "    print(f\"Processing in chunks of {CHUNK_SIZE:,} rows\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    first_chunk = True\n",
    "    total_processed = 0\n",
    "    \n",
    "    # Process file in chunks\n",
    "    for i, chunk in enumerate(pd.read_csv(INPUT_FILE, chunksize=CHUNK_SIZE)):\n",
    "        chunk_start = time.time()\n",
    "        \n",
    "        # Apply categorization to each row\n",
    "        results = chunk.apply(\n",
    "            lambda row: categorize_variable(row['label'], row['variable']), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Add new columns\n",
    "        chunk['category'] = results.apply(lambda x: x[0])\n",
    "        chunk['category_confidence'] = results.apply(lambda x: x[1])\n",
    "        chunk['matched_keywords'] = results.apply(lambda x: x[2])\n",
    "        \n",
    "        # Save to output file\n",
    "        if first_chunk:\n",
    "            chunk.to_csv(OUTPUT_FILE, index=False, mode='w')\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            chunk.to_csv(OUTPUT_FILE, index=False, mode='a', header=False)\n",
    "        \n",
    "        # Progress update\n",
    "        chunk_time = time.time() - chunk_start\n",
    "        total_processed += len(chunk)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(f\"Chunk {i+1}: Processed {len(chunk):,} rows in {chunk_time:.1f}s\")\n",
    "        print(f\"   Total: {total_processed:,} rows | Elapsed: {elapsed:.1f}s\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Processing Complete\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total rows processed: {total_processed:,}\")\n",
    "    print(f\"Total time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"Output saved to: {OUTPUT_FILE}\")\n",
    "    \n",
    "    # Load final results for summary statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Category Distribution\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df_final = pd.read_csv(OUTPUT_FILE)\n",
    "    \n",
    "    category_counts = df_final['category'].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"\\nTotal variables: {len(df_final):,}\\n\")\n",
    "    \n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df_final)) * 100\n",
    "        print(f\"{category:<25} {count:>8,} ({percentage:>5.1f}%)\")\n",
    "    \n",
    "    # Show confidence statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Categorization Confidence\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    high_confidence = len(df_final[df_final['category_confidence'] >= 2])\n",
    "    low_confidence = len(df_final[df_final['category_confidence'] == 1])\n",
    "    no_confidence = len(df_final[df_final['category_confidence'] == 0])\n",
    "    \n",
    "    print(f\"\\nHigh confidence (2+ keywords): {high_confidence:,} ({high_confidence/len(df_final)*100:.1f}%)\")\n",
    "    print(f\"Low confidence (1 keyword):    {low_confidence:,} ({low_confidence/len(df_final)*100:.1f}%)\")\n",
    "    print(f\"No match (OTHER category):     {no_confidence:,} ({no_confidence/len(df_final)*100:.1f}%)\")\n",
    "    \n",
    "    # Sample variables from each category\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Sample Variables by Category\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for category in sorted(df_final['category'].unique()):\n",
    "        sample = df_final[df_final['category'] == category].head(3)\n",
    "        if len(sample) > 0:\n",
    "            print(f\"\\n{category}:\")\n",
    "            for idx, row in sample.iterrows():\n",
    "                print(f\"  - {row['variable']}: {row['label'][:60]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Categorization complete!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# ==============================================================================\n",
    "# RUN SCRIPT\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - bayesian non-parametrics\n",
    "# - MMR \n",
    "# - Make embeddings and then have clusters, make the category search transferable\n",
    "# - GeoTable + LLM Query PoC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
